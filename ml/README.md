This directory contains the implementation of the PoEconomy currency price prediction system, built with industry best practices and enterprise-grade architecture.

## üèóÔ∏è Architecture Overview

The pipeline follows a modular, scalable architecture with clear separation of concerns:

```
ml/
‚îú‚îÄ‚îÄ config/                     # Centralized configuration management
‚îÇ   ‚îî‚îÄ‚îÄ training_config.py      # Complete ML configuration system
‚îú‚îÄ‚îÄ utils/                      # Reusable utility modules
‚îÇ   ‚îú‚îÄ‚îÄ logging_utils.py        # Comprehensive logging and monitoring
‚îÇ   ‚îú‚îÄ‚îÄ data_processing.py      # Data validation and feature engineering
‚îÇ   ‚îú‚îÄ‚îÄ model_training.py       # Model training and hyperparameter optimization
‚îÇ   ‚îú‚îÄ‚îÄ database.py             # Database connectivity
‚îÇ   ‚îú‚îÄ‚îÄ identify_target_currencies.py  # Currency selection logic
‚îÇ   ‚îú‚îÄ‚îÄ backup_postgres.py      # Database backup utilities
‚îÇ   ‚îî‚îÄ‚îÄ insert_currency_prices.py      # Data insertion utilities
‚îú‚îÄ‚îÄ scripts/                    # Pipeline scripts
‚îÇ   ‚îú‚îÄ‚îÄ feature_engineering.py  # Feature engineering pipeline
‚îÇ   ‚îî‚îÄ‚îÄ train_models.py         # Model training pipeline
‚îú‚îÄ‚îÄ models/                     # Trained model artifacts
‚îú‚îÄ‚îÄ training_data/             # Processed training datasets
‚îî‚îÄ‚îÄ logs/                      # Comprehensive logging output
```
## üöÄ Quick Start

### 1. Feature Engineering
```bash
# Standard feature engineering
cd ml/scripts
python feature_engineering.py

# With parallel processing (faster)
python feature_engineering.py --parallel

# Custom experiment
python feature_engineering.py --experiment-id my_experiment --description "Testing new features"
```

### 2. Model Training

#### Quick Pipeline Verification (‚ö° 30 seconds)
```bash
# Ultra-fast test mode - verifies entire pipeline is working
python scripts/test_pipeline.py

# Or using the parallel training script
python scripts/train_models_parallel.py --mode test --monitor-resources
```

#### Production Training
```bash
# Full production training with parallel optimization (recommended)
python scripts/train_models_parallel.py --mode production --monitor-resources

# Traditional sequential training
python scripts/train_models.py --mode production
```

#### Development Training
```bash
# Faster development training with parallel optimization
python scripts/train_models_parallel.py --mode development --monitor-resources

# Traditional development mode
python scripts/train_models.py --mode development
```

#### Train ALL Currencies
```bash
# Train ALL currencies with sufficient data (regardless of value)
python scripts/train_models_parallel.py --train-all-currencies

# Train ALL currencies with custom thresholds
python scripts/train_models.py --train-all-currencies --min-avg-value 0.1 --min-records 50
```

### 3. Configuration Management
```python
from config.training_config import get_production_config, MLConfig

# Use predefined configuration
config = get_production_config()

# Or load from file
config = MLConfig.from_file('my_config.json')

# Customize and save
config.model.n_trials = 100
config.save('custom_config.json')
```

## üìä Configuration System

### Environment-Specific Configurations

#### Production Configuration
- **200 hyperparameter trials** for optimal performance
- **5-fold cross-validation** for robust evaluation
- **Full logging** with structured output
- **Model artifact saving** enabled

#### Development Configuration
- **50 hyperparameter trials** for faster iteration
- **3-fold cross-validation** for quicker feedback
- **Debug logging** for detailed troubleshooting
- **Reduced data requirements** for testing

#### Test Configuration (‚ö° Fast Verification)
- **3 hyperparameter trials** for ultra-fast completion (~30 seconds)
- **2-fold cross-validation** for minimal validation
- **Single currency training** (1 out of 99 available)
- **2 parallel workers** to test parallelization
- **Full resource monitoring** to verify CPU utilization
- **Complete pipeline coverage** (data loading, feature engineering, training)

Perfect for:
- ‚úÖ Quick development verification
- ‚úÖ CI/CD pipeline validation  
- ‚úÖ System health checks
- ‚úÖ Debugging setup issues

### Configuration Structure
```python
@dataclass
class MLConfig:
    model: ModelConfig          # Model training parameters
    data: DataConfig           # Data processing parameters
    processing: ProcessingConfig # Feature engineering strategies
    paths: PathConfig          # File and directory paths
    logging: LoggingConfig     # Logging configuration
    experiment: ExperimentConfig # Experiment tracking
```

## üîß Utility Modules

### Logging Utilities (`utils/logging_utils.py`)
```python
from utils.logging_utils import setup_ml_logging, MLLogger

# Setup comprehensive logging
logger = setup_ml_logging(
    name="MyExperiment",
    level="INFO",
    log_dir="./logs",
    experiment_id="exp_001"
)

# Structured logging with metadata
logger.info("Training started", extra={"model_type": "ensemble"})

# Operation timing
with logger.log_operation("Model training"):
    # Your training code here
    pass
```

### Data Processing (`utils/data_processing.py`)
```python
from utils.data_processing import DataProcessor, DataValidator

# Comprehensive data validation
validator = DataValidator(config.data)
validation_result = validator.validate_dataframe(df, "chaos_orb")

# Feature engineering pipeline
processor = DataProcessor(config.data, config.processing)
processed_data, metadata = processor.process_currency_data(df, "chaos_orb")
```

### Model Training (`utils/model_training.py`)
```python
from utils.model_training import ModelTrainer, save_model_artifacts

# Model training
trainer = ModelTrainer(config.model, logger)
result = trainer.train_single_model(X, y, "chaos_orb")

# Save model artifacts
saved_files = save_model_artifacts(result, output_dir, "chaos_orb")
```

### Currency Selection (`utils/identify_target_currencies.py`)
```python
from utils.identify_target_currencies import generate_target_currency_list

# Get prioritized list of currency pairs for training
target_currencies = generate_target_currency_list()
print(f"Training {len(target_currencies)} currency pairs")
```

### Database Utilities (`utils/database.py`)
```python
from utils.database import get_db_connection

# Database connectivity
conn = get_db_connection()
df = pd.read_sql_query("SELECT * FROM currency_prices", conn)
conn.close()
```

## üìà Performance Monitoring

### Experiment Tracking
Every experiment generates comprehensive reports:
- **Unique experiment IDs** for reproducibility
- **Configuration snapshots** for exact replication
- **Performance metrics** across all models
- **Resource usage** and timing information
- **Error analysis** and failure modes

### Model Evaluation
- **Cross-validation scores** for robustness assessment
- **Settlers league evaluation** for real-world validation
- **Feature importance** analysis
- **Directional accuracy** for trading relevance
- **MAPE, RMSE, MAE** for comprehensive evaluation

## üîç Troubleshooting

### Common Issues

#### Memory Issues
```bash
# Use smaller batch sizes
python train_models.py --mode development

# Or reduce the number of trials
python train_models.py --config reduced_config.json
```

#### Database Connection
```python
# Check database connectivity
from utils.database import get_db_connection
conn = get_db_connection()
print("Database connected successfully!")
```

#### Configuration Errors
```python
# Validate configuration
config = MLConfig.from_file('my_config.json')
print(config.to_dict())  # Check all settings
```

### Performance Optimization

#### Parallel Processing
```bash
# Enable parallel feature engineering
python feature_engineering.py --parallel

# Adjust worker count in configuration
config.processing.max_workers = 4
```

#### Memory Management
```python
# Monitor memory usage
import psutil
print(f"Memory usage: {psutil.virtual_memory().percent}%")
```

## üìö Migration Guide

1. **Update imports** to use new utility modules
2. **Replace configuration** with centralized system
3. **Update logging** to use structured logging
4. **Migrate scripts** to use updated versions
5. **Test thoroughly** with development configuration

### Configuration Migration
```python
config = get_production_config()
config.model.min_samples_required = 150
config.model.n_trials = 200
```